---
title: "Compile updated fire history from Alaska and Canada and combine for AKVeg-Map and other applications"
output: html_document
date: "2024-04-23"
---

Author: Matt Macander, ABR
Usage: Script should be executed in R 4.3.1+.
Description: Scripts in 05a_data_disturbance compile and harmonize the latest fire history data for use in AKVeg-Map and other applications.

# Fire History Compilation, April 2025

Includes final 2024 fire polygons for Alaska, Canada through 2023 and 'some' 2024 fire polygons for Canada 

## Alaska

### Alaska Fire Polygons, downloaded 2025-04-18:

https://fire.ak.blm.gov/predsvcs/maps.php

Data and Metadata -> Zipped Geodatabases -> Alaska Fire History PerimeterPolygons

Best / only data currently available prior to 1999, use Landfire for 1999 to present

## Alaska Landfire, compilation with severity/inclusions

https://landfire.gov/data/FullExtentDownloads

All Years Annual Disturbance, 1999-present covered 1999-2023 as of 2025-04-18
2024 'Preliminary Annual Disturbance' is most complete for 2024 available as of 2025-04-18

## Canada, downloaded 2025-04-18

### NBAC (National Burned Area Composite)

Shapefile, but based largely on raster analysis of burned area that excludes unburned inclusions

https://cwfis.cfs.nrcan.gc.ca/downloads/nbac/

Now NBAC covers 1972-2023, still not 2024

### Some preliminary 2024 Canada firescars

https://pub.data.gov.bc.ca/datasets/cdfc2d7b-c046-4bf0-90ac-4897232619e1/

### NFDB (National Fire Database)

CAN historical NFDB, not updated since 2021 or so
https://cwfis.cfs.nrcan.gc.ca/datamart/download/nfdbpoly

# Fire History Mapping, combining best available data from Alaska and Canada

## Canada

Use Canada NBAC rasterized to 3338 30-m as is (they are largely satellite based and reflect unburned inclusions, etc. natively)

```{bash annual rasters from nbac shapefile}
cd /data/gis/raster_base/Alaska/AKVegMap/disturbance
mkdir -p nbac/v20240530/noncog

for year in `seq 1972 2023`; do
gdal_rasterize \
  -tr 30 30 \
  -te 433005 300015 5400015 4600005  \
  -a YEAR \
  -where "YEAR = ${year}" \
  -a_srs EPSG:3338 \
  -ot UInt16 \
  -of GTiff \
  -co COMPRESS=DEFLATE \
  /data/gis/vector_base/Canada/Fire_History/20250418/nbac_1972_2023_20240530_3338.shp \
  nbac/v20240530/noncog/noncog_nbac_30m_3338_v20240530_${year}.tif

gdal_translate -of cog -co COMPRESS=DEFLATE nbac/v20240530/noncog/noncog_nbac_30m_3338_v20240530_${year}.tif nbac/v20240530/nbac_30m_3338_v20240530_${year}.tif
done

gsutil cp nbac/v20240530/*.tif gs://akveg-data/disturbance/nbac/v20240530/.

# Run nbac_annual_to_cog_ic.ipynb to create cog-backed image collection
```

## Alaska

1. Mask Canada portion to remove from Landfire rasters (GEE). Use built-in mask from year 1 (1999-2014, Landfire ended at Alaska/Canada boundary)

1. Simplify Landfire disturbance codes to disturbance mechanism (fire or other) and severity

Landfire reclass setup
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(RPostgres)
library(dbplyr)
library(lubridate)
library(fs)
library(glue)
library(janitor)
library(purrr)
library(sf)
library(mapview)
library(ranger)
library(gdalUtilities)
library(terra)
library(exifr)
library(exactextractr)
library(spsurvey)
library(readxl)
library(flextable)
library(ftExtra)
library(officer)
library(here)
library(foreign)
library(datapasta)

if (.Platform$OS.type == "unix") {
  p <- "/home/shared/projects/"
  w <- "/data/gis/"
} else {
  p <- "P:/"
  w <- "W:/"
}

options(scipen = 999)

geeDir <- path(w, "gis_base/GEE/GEE_Exports")
```

```{r landfire vats}
#Manual ESRI lookups, background cleanup and 8-bit conversions

severity_vat <- foreign::read.dbf(path(w, "/raster_base/Alaska/Statewide/Vegetation/Alaska_Landfire/2023/HDist/LF2023_HDist_240_AK/Tif/LA23_HDst_240_SEVERITY_na0.tif.vat.dbf")) |>
  rename(severity_co = Value, severity_de = SEVERITY)

dist_type_vat <- foreign::read.dbf(path(w, "raster_base/Alaska/Statewide/Vegetation/Alaska_Landfire/2023/HDist/LF2023_HDist_240_AK/Tif/LA23_HDst_240_DIST_TYPE_u8.tif.vat.dbf")) |>
  rename(distType_co = Value, distType_de = DIST_TYPE)

dist_yr_vat <- foreign::read.dbf(path(w, "raster_base/Alaska/Statewide/Vegetation/Alaska_Landfire/2023/HDist/LF2023_HDist_240_AK/Tif/LA23_HDst_240_HDIST_YR.tif.vat.dbf"))


```

```{r get individual DBF files}
# Define folder path (change to your directory)
folder_path <- path(w, "/raster_base/Alaska/Statewide/Vegetation/Alaska_Landfire/2024/AKAnnualDisturbance_1999_present")

# Find all .dbf files recursively
dbf_files <- dir_ls(folder_path, glob = "*Tif/*.dbf", recurse = TRUE)

folder_path_2024 <- path(w, "/raster_base/Alaska/Statewide/Vegetation/Alaska_Landfire/2024/LF2024_PDist_250_AK")
dbf_file_p2024 <- dir_ls(folder_path_2024, glob = "*Tif/*.dbf", recurse = TRUE)

dbf_files = c(dbf_files, dbf_file_p2024)
# Import and combine .dbf files with cleaned column names
combined_disturbance_df_raw <- bind_rows(lapply(dbf_files, function(file) {
  tryCatch({
    data <- read.dbf(file) %>%
      clean_names() %>%                   # Clean column names
      mutate(across(everything(), as.character))  # Standardize as character
    data$source_path <- file              # Add source file column
    data
  }, error = function(e) {
    message(paste("Failed to read:", file))
    NULL
  })
}))

combined_disturbance_df_raw_check <- combined_disturbance_df_raw |>
  filter(value %in% c(910, 960, 970, 971, 980, 1000, 1001, 1010, 1040, 1060))

combined_disturbance_df <- combined_disturbance_df_raw |>
  mutate(source_file = path_file(source_path)) |>
  mutate(value = as.integer(value),
         count = as.numeric(count),
         dist_type_agg = case_when(dist_type %in% c('Wildfire','Wildland Fire','Wildland Fire Use', 'Prescribed Fire') ~ 'Fire',
                                   TRUE ~ dist_type),
         source_base = str_split_i(source_file, '\\.', 1),
         dist_year = coalesce(year, dist_year, calendar_y),
         source_year = case_when(str_starts(source_base, 'ak') ~ str_sub(source_base, 8, 11),
                                     TRUE ~ str_sub(source_base, 3, 4)),
         source_year = as.numeric(source_year),
         source_year = case_when(source_year < 1000 ~ source_year + 2000,
                                 TRUE ~ source_year),
         severity_orig = severity,
         # Within disturbance perimeter but severity not mapped, e.g. SLC-Off gaps. Will over-map inclusions and approx edges
         severity = case_when(value %in% c(910, 960, 970, 971, 980, 1000, 1001, 1010, 1040, 1060) ~ 'No Severity', 
                              TRUE ~ severity_orig)) |>
  select(source_base, value, dist_year, dist_type_agg, severity, dist_type, descriptio, confidence, type_confi, sev_confid, 
         source1, source2, source3, source4, sev_source, everything())

check_year <- combined_disturbance_df |>
  # filter(!is.na(year) & !is.na(dist_year))
  filter(source_year != dist_year)

# Remove prior year disturbance from 2024 pdist
combined_disturbance_df <- combined_disturbance_df %>%
  filter(!(dist_year == 2023 & source_year == 2024))

severities <- combined_disturbance_df |>
  select(severity) |>
  distinct() 
  
# tribble_paste(severities)

ref_severity = tibble::tribble(
                                ~severity, ~sev_co,
                                       NA, 0,
                                     "NA", 0,
                            "Fill-NoData", 0,
             "Nodata/Non-processing mask", 0, # Excluded as non-burnable landcover, e.g. water
                        "Increased Green", 1,
                           "Unburned/Low", 2,
                                    "Low", 3,
                           "Low-Moderate", 4,
                             "Low-Medium", 4,
                             "Medium-Low", 4,
                                 "Medium", 5,
                               "Moderate", 5,
                            "Medium-High", 6,
                          "Moderate-High", 6,
                            "High-Medium", 6,
                                   "High", 7,
                            "No Severity", 8  # Severity Not Mapped, e.g. cloudy post-fire imagery
             )

dist_types <- combined_disturbance_df |>
  select(dist_type_agg, dist_type) |>
  distinct() |>
  arrange(dist_type_agg, dist_type)

# tribble_paste(dist_types)

ref_dist_type = tibble::tribble(
        ~dist_type_agg,          ~dist_type,  ~dist_type_agg2,
          "Biological",        "Biological", "Other",
            "Chemical",          "Chemical", "Other",
            "Clearcut",          "Clearcut", "Other",
         "Development",       "Development", "Other",
             "Disease",           "Disease", "Other",
         "Fill-NoData",       "Fill-NoData",  "None",
                "Fire",              "Fire",  "Fire",
                "Fire",   "Prescribed Fire",  "Fire",
                "Fire",          "Wildfire",  "Fire",
                "Fire",     "Wildland Fire",  "Fire",
                "Fire", "Wildland Fire Use",  "Fire",
             "Harvest",           "Harvest", "Other",
           "Herbicide",         "Herbicide", "Other",
             "Insects",           "Insects", "Other",
     "Insects/Disease",   "Insects/Disease", "Other",
         "Mastication",       "Mastication", "Other",
                  "NA",                "NA",  "None",
              "NoData",            "NoData",  "None",
    "Other Mechanical",  "Other Mechanical", "Other",
      "Mechanical Add",    "Mechanical Add", "Other",
   "Mechanical Remove", "Mechanical Remove", "Other",
            "Thinning",          "Thinning", "Other",
             "Unknown",           "Unknown", "Other",
               "Water",             "Water", "Other",
             "Weather",           "Weather", "Other",
                    NA,                  NA,  "None",
    ) |>
  left_join(tribble(
    ~dist_co, ~dist_type_agg2,
     0, "None",
    10, "Fire",
    20, "Other"
  ))

combined_disturbance_df_join <- combined_disturbance_df |>
  left_join(ref_severity) |>
  left_join(ref_dist_type) |>
  mutate(distsev_co = dist_co + sev_co) |>
  select(source_base, value, distsev_co, dist_co, sev_co, everything())

combined_disturbance_df_join |> group_by(distsev_co) |> tally()
```


```{r reclass}
remap_tbl <- combined_disturbance_df_join |>
  select(source_year, source_base, source_path, value, distsev_co) |>
  mutate(source_path = path_ext_remove(source_path),
         source_path = path_ext_remove(source_path),
         out_path = path('/data/gis/raster_base/Alaska/Statewide/Vegetation/Alaska_Landfire/2024/AKAnnualDisturbance_1999_present/reclass_noncog', 
                         glue('{source_base}_distsev_co_noncog.tif'))) 

dir_create('/data/gis/raster_base/Alaska/Statewide/Vegetation/Alaska_Landfire/2024/AKAnnualDisturbance_1999_present/reclass_noncog', mode='2775')
          
result <- remap_tbl %>%
  group_by(source_path, out_path) %>%
  group_split() %>%
  lapply(function(group) {
    tif <- unique(group$source_path)
    r <- rast(tif)
    rcl <- as.matrix(group[, c("value", "distsev_co")])
    classify(r, rcl, filename=unique(group$out_path), datatype='INT1U')
  })


# Convert to JavaScript-style lists
result <- remap_tbl %>%
  group_by(source_year, source_base) %>%
  summarise(
    from = paste0("[", paste(value, collapse = ", "), "]"),
    to = paste0("[", paste(distsev_co, collapse = ", "), "]")
  ) %>%
  ungroup() %>%
  arrange(source_year) %>%
  mutate(bandName = glue('b{row_number()}'), .before=1)

# Format as text string
formatted_text <- result %>%
  # mutate(text = paste0("'", bandName, "', ", from, ", ", to)) %>%
  mutate(text = glue("var dist_agg_{source_year} = annual_dist_stack.select('{bandName}').rename('lf_raw').addBands(annual_dist_stack.select('{bandName}').remap({from}, {to}, 99).rename('lf_agg'));")) %>%
  pull(text) %>%
  paste(collapse = "\n")

# Print output
cat(formatted_text)

```

3. For fire, and with severity codes that indicate uncertainty of whether there was a fire, intersect with GABAM
4. Save simplified severities (fire only) with extra GABAM info where relevant
5. Save annual rasters of Landfire fire + GABAM codes

3. Do not use AK fire polys except for pre-Landfire years




```{r setup, include=FALSE, eval=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(terra)
library(tidyverse)
library(fs)
library(sf)
library(tictoc)
library(exactextractr)
# library(gdalUtils)
library(glue)
library(mapview)
# library(solrad)
library(gdalUtilities)

w <- '/data/gis/'

```

Ingest and standardize on 3338
```{r ingest and standardize on 3338, eval=FALSE}
ak_firepoly <- read_sf(path(w, 'vector_base/Alaska/Statewide/Fire/20250418/AlaskaFireHistory_Polygons.gdb'),
                       layer='AK_fire_location_polygons_AKAlbersNAD83') %>%
  rename(geometry = Shape) %>%
  select(fire_year = FIREYEAR) %>%
  mutate(source = 'AK_fire_location_polygons_AKAlbersNAD83 with 2024, downloaded 2024-04-18',
         fire_year = as.integer(fire_year))

#1972-2022
can_nbac <- read_sf(path(w, 'vector_base/Canada/Fire_History/20250418/nbac_1972_2023_20240530.shp')) %>%
  # rename(geometry = Shape) %>%
  select(fire_year = YEAR) %>%
  mutate(source = 'nbac_1972_to_2023_20240530.shp') %>%
  st_make_valid() %>%
  st_transform(3338)

#2024
can_2024 <- read_sf(path(w, 'vector_base/Canada/Fire_History/20250418/prot_current_fire_polys.shp')) %>%
  # rename(geometry = Shape) %>%
  select(fire_year = FIRE_YEAR) %>%
  mutate(source = 'prot_current_fire_polys.shp for 2024, downloaded 2025-04-18') %>%
  st_make_valid() %>%
  st_transform(3338)

# can_nfdb <- read_sf(path(w, 'vector_base/Canada/Fire_History/20240308/NFDB_poly 20240308/NFDB_poly_20210707.shp')) %>%
#   # rename(geometry = Shape) %>%
#   select(fire_year = YEAR, DECADE) %>%
#   st_make_valid()
  
#Pre-1972
can_nfdb_thru_1971 <- read_sf(path(w, 'vector_base/Canada/Fire_History/20240308/NFDB_poly 20240308/NFDB_poly_20210707_thru_1971_and_UNK.shp')) %>%
  select(fire_year = YEAR, DECADE) %>%
  st_make_valid() %>%
  mutate(source = 'NFDB_poly_20210707.shp through 1971') %>%
  #Exclude fires from NBAC record and -9999 fires
  filter(between(fire_year, 0, 1971)) %>%
  st_transform(3338) %>%
  select(fire_year, source)

#Unknown but decade known
can_nfdb_unk <- read_sf(path(w, 'vector_base/Canada/Fire_History/20240308/NFDB_poly 20240308/NFDB_poly_20210707_thru_1971_and_UNK.shp')) %>%
  select(fire_year = YEAR, DECADE) %>%
  st_make_valid() %>%
  mutate(source = 'NFDB_poly_20210707.shp, estimated fire_year based on decade') %>%
  #-9999 fires, refer to decade
  filter(fire_year == -9999) %>%
  st_transform(3338) %>%
  mutate(fire_year_start = as.integer(str_split_i(DECADE, '-', 1)),
         fire_year_end   = as.integer(str_split_i(DECADE, '-', 2)),
         fire_year = fire_year_start + 5) %>%
  select(fire_year, source)

can_firepoly_3338 <- bind_rows(can_nfdb_thru_1971, can_nbac, can_2024, can_nfdb_unk) %>%
  arrange(fire_year)

ak_above <- read_sf(path(w, 'gis_projects/2022/22-301_NASA_ABoVE_Biome_Shift/akvegmap_v2/studyAreas',
                    'ABoVE_Alaska_3parts_Buff10km_BuffMinus5km_Simplify5km_3338_v20230328.shp')) %>%
  st_zm(drop=T)
ak_above


ak_above_union <- st_union(ak_above)

akcan_firepoly_3338 <- bind_rows(ak_firepoly, can_firepoly_3338) %>%
  arrange(fire_year)
write_sf(akcan_firepoly_3338, path(w, 'vector_base/Alaska/Statewide/Fire/akcan_firepoly_thru_2024_v20250418.shp'))

# can_firepoly_3338_akabove <- st_intersection(can_firepoly_3338, ak_above_union)
# akcan_above_firepoly_3338 <- bind_rows(ak_firepoly, can_firepoly_3338_akabove) %>%
#   arrange(fire_year) %>%
#   st_zm(drop=T)
# write_sf(akcan_above_firepoly_3338, path(w, 'vector_base/Alaska/Statewide/Fire/20250418/akcan_above_firepoly_thru_2024_v20250418.shp'))

by_year <- akcan_firepoly_3338 %>% st_drop_geometry() %>% group_by(fire_year) %>% tally()
akcan_firepoly_3338 %>% st_drop_geometry() %>% group_by(source) %>% tally()

```

Load compiled and harmonized layer and study area
```{r load layers, eval=FALSE}
# akcan_above_firepoly_3338 <- read_sf(path(w, 'vector_base/Alaska/Statewide/Fire/20250418/akcan_above_firepoly_thru_2024_v20250418.shp')) %>%
#   mutate(fire_year = as.integer(fire_year))
# # st_cast needed if using R created object directly but not after reading merged shapefile
# # akcan_firepoly_3338 <- st_cast(akcan_firepoly_3338, 'MULTIPOLYGON')
# akcan_above_firepoly_3338_vect <- vect(akcan_above_firepoly_3338)

akcan_firepoly_3338 <- read_sf(path(w, 'vector_base/Alaska/Statewide/Fire/akcan_firepoly_thru_2024_v20250418.shp')) %>%
  mutate(fire_year = as.integer(fire_year))
akcan_firepoly_3338_vect <- vect(akcan_firepoly_3338)

ak_above <- read_sf(path(w, 'gis_projects/2022/22-301_NASA_ABoVE_Biome_Shift/akvegmap_v2/studyAreas',
                    'ABoVE_Alaska_3parts_Buff10km_BuffMinus5km_Simplify5km_3338_v20230328.shp')) %>%
  st_zm(drop=T)
```

Note, rasterization steps are slow, other tools may be better
Rasterize 30 m raster AK and Canada
```{r rasterize 30 m raster AK and Canada, eval=FALSE}
fire_snap_30m_3338 <- rast(resolution=30, crs='EPSG:3338', extent=c(-15,15,-15,15))
fire_snap_30m_3338

fire_30m_3338 <- extend(fire_snap_30m_3338, akcan_firepoly_3338, snap='out')
fire_30m_3338

#SLOOOOW
# Fix with wopt, but want COG anyway
akcan_fire_rast <- rasterize(akcan_firepoly_3338_vect, fire_30m_3338, 'fire_year', fun='max',# datatype='INT2U',
                          filename='/data/gis/gis_projects/2022/22-301_NASA_ABoVE_Biome_Shift/akvegmap_v2/flt32_mrfy_akcan_1917_2024_30m_3338_v20250418.tif')

gdal_translate('/data/gis/gis_projects/2022/22-301_NASA_ABoVE_Biome_Shift/akvegmap_v2/flt32_mrfy_akcan_1917_2024_30m_3338_v20250418.tif',
               '/data/gis/gis_projects/2022/22-301_NASA_ABoVE_Biome_Shift/akvegmap_v2/mrfy_akcan_1917_2024_30m_3338_v20250418.tif',
               ot='UInt16', of='COG', a_nodata=0, co=c("OVERVIEWS=IGNORE_EXISTING", "RESAMPLING=MODE", "COMPRESS=DEFLATE", "PREDICTOR=2", "BIGTIFF=IF_SAFER", "NUM_THREADS=16"))

#10m version, Alaska and Yukon bbox only
#Note this does make the bbox a bit larger than necessary, (0,0) is a bit south of the data extent
# Use full bounding box of larger Yukon SA vs. the NAB SA
# akyuk_rast <- rast('/data/gis/gis_projects/2019/19-301_ABoVE_Biome_Shift/akvegmap_v2/studyAreas/AKVEG_ModelArea_Rasters_20230330/AlaskaYukon_MapDomain_10m_3338.tif')
# akyuk_sf <- read_sf(path(w, 'gis_projects/2019/19-301_ABoVE_Biome_Shift/akvegmap_v2/studyAreas/AKVEG_Regions_20230330/AKVEG_Regions.gdb'),
                    # layer='AlaskaYukon_MapDomain_3338')

```

Rasterize 10m with smaller study area
```{r rasterize 10m with smaller study area, eval=FALSE}
fire_snap_10m_3338 <- rast(resolution=10, crs='EPSG:3338', extent=c(-5,5,-5,5))
akyuk <- ak_above %>%
  filter(Region == 'North American Beringia and TNP')
fire_10m_3338 <- extend(fire_snap_10m_3338, akyuk, snap='out')
fire_10m_3338

#SLOOOOW
akyuk_fire_rast <- rasterize(akcan_firepoly_3338_vect, fire_10m_3338, 'fire_year', fun='max',
                          filename='/data/gis/gis_projects/2022/22-301_NASA_ABoVE_Biome_Shift/akvegmap_v2/flt32_mrfy_akyuk_1917_2024_10m_3338_v20250418.tif')

gdal_translate('/data/gis/gis_projects/2022/22-301_NASA_ABoVE_Biome_Shift/akvegmap_v2/flt32_mrfy_akyuk_1917_2024_10m_3338_v20250418.tif',
               '/data/gis/gis_projects/2022/22-301_NASA_ABoVE_Biome_Shift/akvegmap_v2/mrfy_akyuk_1917_2024_10m_3338_v20250418.tif',
               ot='UInt16', of='COG', a_nodata=0, co=c("OVERVIEWS=IGNORE_EXISTING", "RESAMPLING=MODE", "COMPRESS=DEFLATE", "PREDICTOR=2", "BIGTIFF=IF_SAFER", "NUM_THREADS=16"))


# Do 30m as AKCAN not AKCAN ABoVE
```


```{r test fasterize on Canada fires}
library()

```
Upload to GEE assets at projects/akveg-map/assets/disturbance



