---
title: "Compile updated fire history from Alaska and Canada and combine for AKVeg-Map and other applications"
output: html_document
date: "2024-04-23"
---

Author: Matt Macander, ABR
Usage: Script should be executed in R 4.3.1+.
Description: Scripts in 05a_data_disturbance compile and harmonize the latest fire history data for use in AKVeg-Map and other applications.

# Fire History Compilation, April 2025

Includes final 2024 fire polygons for Alaska, Canada through 2023 and 'some' 2024 fire polygons for Canada 

## Alaska

### Alaska Fire Polygons, downloaded 2025-04-18:

https://fire.ak.blm.gov/predsvcs/maps.php

Data and Metadata -> Zipped Geodatabases -> Alaska Fire History PerimeterPolygons

Best / only data currently available prior to 1999, use Landfire for 1999 to present

## Alaska Landfire, compilation with severity/inclusions

https://landfire.gov/data/FullExtentDownloads

All Years Annual Disturbance, 1999-present covered 1999-2023 as of 2025-04-18
2024 'Preliminary Annual Disturbance' is most complete for 2024 available as of 2025-04-18

## Canada, downloaded 2025-04-18

### NBAC (National Burned Area Composite)

Shapefile, but based largely on raster analysis of burned area that excludes unburned inclusions

https://cwfis.cfs.nrcan.gc.ca/downloads/nbac/

Now NBAC covers 1972-2023, still not 2024

### Some preliminary 2024 Canada firescars

https://pub.data.gov.bc.ca/datasets/cdfc2d7b-c046-4bf0-90ac-4897232619e1/

### NFDB (National Fire Database)

CAN historical NFDB, not updated since 2021 or so
https://cwfis.cfs.nrcan.gc.ca/datamart/download/nfdbpoly

# Fire History Mapping, combining best available data from Alaska and Canada

## Canada

Use Canada NBAC rasterized to 3338 30-m as is (they are largely satellite based and reflect unburned inclusions, etc. natively)

#TODO CAN Albers 102001 30m version for ABoVE

```{bash annual rasters from nbac shapefile 3338 landfire 2023 extent}
cd /data/gis/raster_base/Alaska/AKVegMap/disturbance
mkdir -p nbac/v20240530/noncog_lf_3338
mkdir -p nbac/v20240530/cog_lf_3338

for year in `seq 1972 2023`; do
echo $year
gdal_rasterize \
  -tr 30 30 \
  -te -2175045 404505 1583055 2383725  \
  -a YEAR \
  -where "YEAR = ${year}" \
  -a_srs EPSG:3338 \
  -ot UInt16 \
  -of GTiff \
  -co COMPRESS=DEFLATE \
  /data/gis/vector_base/Canada/Fire_History/20250418/nbac_1972_2023_20240530_3338.shp \
  nbac/v20240530/noncog_lf_3338/noncog_nbac_30m_3338_v20240530_${year}.tif

gdal_translate -of cog -co COMPRESS=DEFLATE -co NUM_THREADS=20 nbac/v20240530/noncog_lf_3338/noncog_nbac_30m_3338_v20240530_${year}.tif nbac/v20240530/cog_lf_3338/nbac_30m_3338_v20240530_${year}.tif
done

gsutil cp nbac/v20240530/cog_lf_3338/*.tif gs://akveg-data/disturbance/nbac/v20240530/cog_lf_3338/

# Run nbac_annual_to_cog_ic.ipynb to create cog-backed image collection
#  -co NUM_THREADS=20 \


```


```{bash annual rasters from nbac shapefile 102001}
cd /data/gis/raster_base/Alaska/AKVegMap/disturbance
mkdir -p nbac/v20240530/noncog_102001
mkdir -p nbac/v20240530/cog_102001

for year in `seq 1972 2023`; do
gdal_rasterize \
  -tr 30 30 \
  -te -2282865 301365 3066045 3779295 \
  -a YEAR \
  -where "YEAR = ${year}" \
  -a_srs ESRI:102001 \
  -ot UInt16 \
  -of GTiff \
  -co COMPRESS=DEFLATE \
  /data/gis/vector_base/Canada/Fire_History/20250418/nbac_1972_2023_20240530_102001.shp \
  nbac/v20240530/noncog_102001/noncog_nbac_30m_102001_v20240530_${year}.tif

gdal_translate -of cog -co COMPRESS=DEFLATE nbac/v20240530/noncog_102001/noncog_nbac_30m_102001_v20240530_${year}.tif nbac/v20240530/cog_102001/nbac_30m_102001_v20240530_${year}.tif
done

gsutil cp nbac/v20240530/cog_102001/*.tif gs://akveg-data/disturbance/nbac/v20240530/cog_102001/

# Run nbac_annual_to_cog_ic.ipynb to create cog-backed image collection
```

## Alaska

1. Mask Canada portion to remove from Landfire rasters (GEE). Use built-in mask from year 1 (1999-2014, Landfire ended at Alaska/Canada boundary)

2. Simplify Landfire disturbance codes to disturbance mechanism (fire or other) and severity

Landfire reclass setup
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(RPostgres)
library(dbplyr)
library(lubridate)
library(fs)
library(glue)
library(janitor)
library(purrr)
library(sf)
library(mapview)
library(ranger)
library(gdalUtilities)
library(terra)
library(exifr)
library(exactextractr)
library(spsurvey)
library(readxl)
library(flextable)
library(ftExtra)
library(officer)
library(here)
library(foreign)
library(datapasta)

if (.Platform$OS.type == "unix") {
  p <- "/home/shared/projects/"
  w <- "/data/gis/"
} else {
  p <- "P:/"
  w <- "W:/"
}

options(scipen = 999)

geeDir <- path(w, "gis_base/GEE/GEE_Exports")
```

```{r landfire vats}
#Manual ESRI lookups, background cleanup and 8-bit conversions

severity_vat <- foreign::read.dbf(path(w, "/raster_base/Alaska/Statewide/Vegetation/Alaska_Landfire/2023/HDist/LF2023_HDist_240_AK/Tif/LA23_HDst_240_SEVERITY_na0.tif.vat.dbf")) |>
  rename(severity_co = Value, severity_de = SEVERITY)

dist_type_vat <- foreign::read.dbf(path(w, "raster_base/Alaska/Statewide/Vegetation/Alaska_Landfire/2023/HDist/LF2023_HDist_240_AK/Tif/LA23_HDst_240_DIST_TYPE_u8.tif.vat.dbf")) |>
  rename(distType_co = Value, distType_de = DIST_TYPE)

dist_yr_vat <- foreign::read.dbf(path(w, "raster_base/Alaska/Statewide/Vegetation/Alaska_Landfire/2023/HDist/LF2023_HDist_240_AK/Tif/LA23_HDst_240_HDIST_YR.tif.vat.dbf"))


```

```{r get individual DBF files}
# Define folder path (change to your directory)
folder_path <- path(w, "/raster_base/Alaska/Statewide/Vegetation/Alaska_Landfire/2024/AKAnnualDisturbance_1999_present")

# Find all .dbf files recursively
dbf_files <- dir_ls(folder_path, glob = "*Tif/*.dbf", recurse = TRUE)

folder_path_2024 <- path(w, "/raster_base/Alaska/Statewide/Vegetation/Alaska_Landfire/2024/LF2024_PDist_250_AK")
dbf_file_p2024 <- dir_ls(folder_path_2024, glob = "*Tif/*.dbf", recurse = TRUE)

dbf_files = c(dbf_files, dbf_file_p2024)
# Import and combine .dbf files with cleaned column names
combined_disturbance_df_raw <- bind_rows(lapply(dbf_files, function(file) {
  tryCatch({
    data <- read.dbf(file) %>%
      clean_names() %>%                   # Clean column names
      mutate(across(everything(), as.character))  # Standardize as character
    data$source_path <- file              # Add source file column
    data
  }, error = function(e) {
    message(paste("Failed to read:", file))
    NULL
  })
}))

combined_disturbance_df_raw_check <- combined_disturbance_df_raw |>
  filter(value %in% c(910, 960, 970, 971, 980, 1000, 1001, 1010, 1040, 1060))

combined_disturbance_df <- combined_disturbance_df_raw |>
  mutate(source_file = path_file(source_path)) |>
  mutate(value = as.integer(value),
         count = as.numeric(count),
         dist_type_agg = case_when(dist_type %in% c('Wildfire','Wildland Fire','Wildland Fire Use', 'Prescribed Fire') ~ 'Fire',
                                   TRUE ~ dist_type),
         source_base = str_split_i(source_file, '\\.', 1),
         dist_year = coalesce(year, dist_year, calendar_y),
         source_year = case_when(str_starts(source_base, 'ak') ~ str_sub(source_base, 8, 11),
                                     TRUE ~ str_sub(source_base, 3, 4)),
         source_year = as.numeric(source_year),
         source_year = case_when(source_year < 1000 ~ source_year + 2000,
                                 TRUE ~ source_year),
         severity_orig = severity,
         # Within disturbance perimeter but severity not mapped, e.g. SLC-Off gaps. Will over-map inclusions and approx edges
         severity = case_when(value %in% c(910, 960, 970, 971, 980, 1000, 1001, 1010, 1040, 1060) ~ 'No Severity', 
                              TRUE ~ severity_orig)) |>
  select(source_base, value, dist_year, dist_type_agg, severity, dist_type, descriptio, confidence, type_confi, sev_confid, 
         source1, source2, source3, source4, sev_source, everything())

check_year <- combined_disturbance_df |>
  # filter(!is.na(year) & !is.na(dist_year))
  filter(source_year != dist_year)

# Remove prior year disturbance from 2024 pdist
combined_disturbance_df <- combined_disturbance_df %>%
  filter(!(dist_year == 2023 & source_year == 2024))

severities <- combined_disturbance_df |>
  select(severity) |>
  distinct() 
  
# tribble_paste(severities)

ref_severity = tibble::tribble(
                                ~severity, ~sev_co,
                                       NA, 0,
                                     "NA", 0,
                            "Fill-NoData", 0,
             "Nodata/Non-processing mask", 0, # Excluded as non-burnable landcover, e.g. water
                        "Increased Green", 1,
                           "Unburned/Low", 2,
                                    "Low", 3,
                           "Low-Moderate", 4,
                             "Low-Medium", 4,
                             "Medium-Low", 4,
                                 "Medium", 5,
                               "Moderate", 5,
                            "Medium-High", 6,
                          "Moderate-High", 6,
                            "High-Medium", 6,
                                   "High", 7,
                            "No Severity", 8  # Severity Not Mapped, e.g. cloudy post-fire imagery
             )

dist_types <- combined_disturbance_df |>
  select(dist_type_agg, dist_type) |>
  distinct() |>
  arrange(dist_type_agg, dist_type)

# tribble_paste(dist_types)

ref_dist_type = tibble::tribble(
        ~dist_type_agg,          ~dist_type,  ~dist_type_agg2,
          "Biological",        "Biological", "Other",
            "Chemical",          "Chemical", "Other",
            "Clearcut",          "Clearcut", "Other",
         "Development",       "Development", "Other",
             "Disease",           "Disease", "Other",
         "Fill-NoData",       "Fill-NoData",  "None",
                "Fire",              "Fire",  "Fire",
                "Fire",   "Prescribed Fire",  "Fire",
                "Fire",          "Wildfire",  "Fire",
                "Fire",     "Wildland Fire",  "Fire",
                "Fire", "Wildland Fire Use",  "Fire",
             "Harvest",           "Harvest", "Other",
           "Herbicide",         "Herbicide", "Other",
             "Insects",           "Insects", "Other",
     "Insects/Disease",   "Insects/Disease", "Other",
         "Mastication",       "Mastication", "Other",
                  "NA",                "NA",  "None",
              "NoData",            "NoData",  "None",
    "Other Mechanical",  "Other Mechanical", "Other",
      "Mechanical Add",    "Mechanical Add", "Other",
   "Mechanical Remove", "Mechanical Remove", "Other",
            "Thinning",          "Thinning", "Other",
             "Unknown",           "Unknown", "Other",
               "Water",             "Water", "Other",
             "Weather",           "Weather", "Other",
                    NA,                  NA,  "None",
    ) |>
  left_join(tribble(
    ~dist_co, ~dist_type_agg2,
     0, "None",
    10, "Fire",
    20, "Other"
  ))

combined_disturbance_df_join <- combined_disturbance_df |>
  left_join(ref_severity) |>
  left_join(ref_dist_type) |>
  mutate(distsev_co = dist_co + sev_co) |>
  select(source_base, value, distsev_co, dist_co, sev_co, everything())

combined_disturbance_df_join |> group_by(distsev_co) |> tally()
```

// Simplified Scheme:
// 00: No disturbance/fill value
// 10: Fire, severity = Unburnable landcover e.g. water
// 11: Fire, severity = Increased Green 
// 12: Fire, severity = Unburned/Low
// 13: Fire, severity = Low
// 14: Fire, severity = Low-Medium (does not occur for fire)
// 15: Fire, severity = Medium
// 16: Fire, severity = Medium-High (does not occur for fire)
// 17: Fire, severity = High
// 18: Fire, severity = Not Reported
// 20: Other Disturbance, severity = Unaffected landcover e.g. water
// 21: Other Disturbance, severity = Increased Green 
// 22: Other Disturbance, severity = Unburned/Low
// 23: Other Disturbance, severity = Low
// 24: Other Disturbance, severity = Low-Medium
// 25: Other Disturbance, severity = Medium
// 26: Other Disturbance, severity = Medium-High
// 27: Other Disturbance, severity = High
// 28: Other Disturbance, severity = Not Reported


```{r reclass to local cogs}
remap_tbl <- combined_disturbance_df_join |>
  select(source_year, source_base, source_path, value, distsev_co) |>
  mutate(source_path = path_ext_remove(source_path),
         source_path = path_ext_remove(source_path),
         out_path = path('/data/gis/raster_base/Alaska/Statewide/Vegetation/Alaska_Landfire/2024/AKAnnualDisturbance_1999_present/reclass_noncog', 
                         glue('{source_base}_distsev_co_noncog.tif')),
         cog_path = path('/data/gis/raster_base/Alaska/Statewide/Vegetation/Alaska_Landfire/2024/AKAnnualDisturbance_1999_present/reclass_cog', 
                         glue('{source_base}_distsev_co.tif'))) 

dir_create('/data/gis/raster_base/Alaska/Statewide/Vegetation/Alaska_Landfire/2024/AKAnnualDisturbance_1999_present/reclass_noncog', mode='2775')
dir_create('/data/gis/raster_base/Alaska/Statewide/Vegetation/Alaska_Landfire/2024/AKAnnualDisturbance_1999_present/reclass_cog', mode='2775')
          
result <- remap_tbl %>%
  group_by(source_path, out_path, cog_path) %>%
  group_split() %>%
  lapply(function(group) {
    tif <- unique(group$source_path)
    r <- rast(tif)
    rcl <- as.matrix(group[, c("value", "distsev_co")])
    classify(r, rcl, filename=unique(group$out_path), others=NA, datatype='INT1U', overwrite=TRUE)
    gdal_translate(unique(group$out_path), 
                   unique(group$cog_path),
                   of="COG",
                   config_options=c( 
                             COMPRESS="DEFLATE",
                             NUMTHREADS=20)
    )
  })

```

Convert to GEE remap lists to reclass on GEE. Assumes that full Annual Landfire disturbance rasters already loaded in GEE.
```{r old, convert remap to lists that can be copied over to GEE code editor}
# Convert to JavaScript-style lists
result <- remap_tbl %>%
  group_by(source_year, source_base) %>%
  summarise(
    from = paste0("[", paste(value, collapse = ", "), "]"),
    to = paste0("[", paste(distsev_co, collapse = ", "), "]")
  ) %>%
  ungroup() %>%
  arrange(source_year) %>%
  mutate(bandName = glue('b{row_number()}'), .before=1)

# Format as text string
formatted_text <- result %>%
  # mutate(text = paste0("'", bandName, "', ", from, ", ", to)) %>%
  mutate(text = glue("var dist_agg_{source_year} = annual_dist_stack.select('{bandName}').rename('lf_raw').addBands(annual_dist_stack.select('{bandName}').remap({from}, {to}, 99).rename('lf_agg'));")) %>%
  pull(text) %>%
  paste(collapse = "\n")

# Print output
cat(formatted_text)

```

3. Parse fire pixels. If they have severity codes that indicate uncertainty as to whether there was a fire, intersect with GABAM. Save annual simplified severities (fire only) with extra GABAM info where relevant.

https://code.earthengine.google.com/92d918051bc840ff04e403107fe64520 (2025-04-30)
https://code.earthengine.google.com/?scriptPath=users%2Fmmacander%2Fakveg_map%3Adisturbance%2Fexport_annual_landfire_x_gabam

Exports annual Alaska fire maps (combining Landfire and GABAM) for 1999-2024 to:
projects/akveg-map/assets/disturbance/landfire_fire_x_gabam

4. Combine (Landfire + GABAM, masked to Alaska only) + (Canada NBAC) for annual fire extent rasters for annual rasters 2000-2022, 2000-2023, 2000-2024 for simple masks

https://code.earthengine.google.com/?scriptPath=users%2Fmmacander%2Fakveg_map%3Adisturbance%2Fcombine_alaska_canada_firepixels

5. Create MRFY layer for 2000-2022, 2000-2023, 2000-2024

Same as script above.

Export split to avoid projection issues. Both include Alaska and Canada fire pixels.

Alaska bounding box (full extent of input Landfire, includes AKVeg study area with Yukon)
Canada bounding box (full extent of NBAC)

Each of the 3 Landfire/GABAM methods exported as separate raster




####################

OLD merge of fire polygons (polygons are not best source for Alaska except for prior to 1999)
```{r setup, include=FALSE, eval=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(terra)
library(tidyverse)
library(fs)
library(sf)
library(tictoc)
library(exactextractr)
# library(gdalUtils)
library(glue)
library(mapview)
# library(solrad)
library(gdalUtilities)

w <- '/data/gis/'

```

Ingest and standardize on 3338
```{r ingest and standardize on 3338, eval=FALSE}
ak_firepoly <- read_sf(path(w, 'vector_base/Alaska/Statewide/Fire/20250418/AlaskaFireHistory_Polygons.gdb'),
                       layer='AK_fire_location_polygons_AKAlbersNAD83') %>%
  rename(geometry = Shape) %>%
  select(fire_year = FIREYEAR) %>%
  mutate(source = 'AK_fire_location_polygons_AKAlbersNAD83 with 2024, downloaded 2024-04-18',
         fire_year = as.integer(fire_year))

#1972-2022
can_nbac <- read_sf(path(w, 'vector_base/Canada/Fire_History/20250418/nbac_1972_2023_20240530.shp')) %>%
  # rename(geometry = Shape) %>%
  select(fire_year = YEAR) %>%
  mutate(source = 'nbac_1972_to_2023_20240530.shp') %>%
  st_make_valid() %>%
  st_transform(3338)

#2024
can_2024 <- read_sf(path(w, 'vector_base/Canada/Fire_History/20250418/prot_current_fire_polys.shp')) %>%
  # rename(geometry = Shape) %>%
  select(fire_year = FIRE_YEAR) %>%
  mutate(source = 'prot_current_fire_polys.shp for 2024, downloaded 2025-04-18') %>%
  st_make_valid() %>%
  st_transform(3338)

# can_nfdb <- read_sf(path(w, 'vector_base/Canada/Fire_History/20240308/NFDB_poly 20240308/NFDB_poly_20210707.shp')) %>%
#   # rename(geometry = Shape) %>%
#   select(fire_year = YEAR, DECADE) %>%
#   st_make_valid()
  
#Pre-1972
can_nfdb_thru_1971 <- read_sf(path(w, 'vector_base/Canada/Fire_History/20240308/NFDB_poly 20240308/NFDB_poly_20210707_thru_1971_and_UNK.shp')) %>%
  select(fire_year = YEAR, DECADE) %>%
  st_make_valid() %>%
  mutate(source = 'NFDB_poly_20210707.shp through 1971') %>%
  #Exclude fires from NBAC record and -9999 fires
  filter(between(fire_year, 0, 1971)) %>%
  st_transform(3338) %>%
  select(fire_year, source)

#Unknown but decade known
can_nfdb_unk <- read_sf(path(w, 'vector_base/Canada/Fire_History/20240308/NFDB_poly 20240308/NFDB_poly_20210707_thru_1971_and_UNK.shp')) %>%
  select(fire_year = YEAR, DECADE) %>%
  st_make_valid() %>%
  mutate(source = 'NFDB_poly_20210707.shp, estimated fire_year based on decade') %>%
  #-9999 fires, refer to decade
  filter(fire_year == -9999) %>%
  st_transform(3338) %>%
  mutate(fire_year_start = as.integer(str_split_i(DECADE, '-', 1)),
         fire_year_end   = as.integer(str_split_i(DECADE, '-', 2)),
         fire_year = fire_year_start + 5) %>%
  select(fire_year, source)

can_firepoly_3338 <- bind_rows(can_nfdb_thru_1971, can_nbac, can_2024, can_nfdb_unk) %>%
  arrange(fire_year)

ak_above <- read_sf(path(w, 'gis_projects/2022/22-301_NASA_ABoVE_Biome_Shift/akvegmap_v2/studyAreas',
                    'ABoVE_Alaska_3parts_Buff10km_BuffMinus5km_Simplify5km_3338_v20230328.shp')) %>%
  st_zm(drop=T)
ak_above


ak_above_union <- st_union(ak_above)

akcan_firepoly_3338 <- bind_rows(ak_firepoly, can_firepoly_3338) %>%
  arrange(fire_year)
write_sf(akcan_firepoly_3338, path(w, 'vector_base/Alaska/Statewide/Fire/akcan_firepoly_thru_2024_v20250418.shp'))

# can_firepoly_3338_akabove <- st_intersection(can_firepoly_3338, ak_above_union)
# akcan_above_firepoly_3338 <- bind_rows(ak_firepoly, can_firepoly_3338_akabove) %>%
#   arrange(fire_year) %>%
#   st_zm(drop=T)
# write_sf(akcan_above_firepoly_3338, path(w, 'vector_base/Alaska/Statewide/Fire/20250418/akcan_above_firepoly_thru_2024_v20250418.shp'))

by_year <- akcan_firepoly_3338 %>% st_drop_geometry() %>% group_by(fire_year) %>% tally()
akcan_firepoly_3338 %>% st_drop_geometry() %>% group_by(source) %>% tally()

```

Load compiled and harmonized layer and study area
```{r load layers, eval=FALSE}
# akcan_above_firepoly_3338 <- read_sf(path(w, 'vector_base/Alaska/Statewide/Fire/20250418/akcan_above_firepoly_thru_2024_v20250418.shp')) %>%
#   mutate(fire_year = as.integer(fire_year))
# # st_cast needed if using R created object directly but not after reading merged shapefile
# # akcan_firepoly_3338 <- st_cast(akcan_firepoly_3338, 'MULTIPOLYGON')
# akcan_above_firepoly_3338_vect <- vect(akcan_above_firepoly_3338)

akcan_firepoly_3338 <- read_sf(path(w, 'vector_base/Alaska/Statewide/Fire/akcan_firepoly_thru_2024_v20250418.shp')) %>%
  mutate(fire_year = as.integer(fire_year))
akcan_firepoly_3338_vect <- vect(akcan_firepoly_3338)

ak_above <- read_sf(path(w, 'gis_projects/2022/22-301_NASA_ABoVE_Biome_Shift/akvegmap_v2/studyAreas',
                    'ABoVE_Alaska_3parts_Buff10km_BuffMinus5km_Simplify5km_3338_v20230328.shp')) %>%
  st_zm(drop=T)
```

Note, rasterization steps are slow, other tools may be better
Rasterize 30 m raster AK and Canada
```{r rasterize 30 m raster AK and Canada, eval=FALSE}
fire_snap_30m_3338 <- rast(resolution=30, crs='EPSG:3338', extent=c(-15,15,-15,15))
fire_snap_30m_3338

fire_30m_3338 <- extend(fire_snap_30m_3338, akcan_firepoly_3338, snap='out')
fire_30m_3338

#SLOOOOW
# Fix with wopt, but want COG anyway
akcan_fire_rast <- rasterize(akcan_firepoly_3338_vect, fire_30m_3338, 'fire_year', fun='max',# datatype='INT2U',
                          filename='/data/gis/gis_projects/2022/22-301_NASA_ABoVE_Biome_Shift/akvegmap_v2/flt32_mrfy_akcan_1917_2024_30m_3338_v20250418.tif')

gdal_translate('/data/gis/gis_projects/2022/22-301_NASA_ABoVE_Biome_Shift/akvegmap_v2/flt32_mrfy_akcan_1917_2024_30m_3338_v20250418.tif',
               '/data/gis/gis_projects/2022/22-301_NASA_ABoVE_Biome_Shift/akvegmap_v2/mrfy_akcan_1917_2024_30m_3338_v20250418.tif',
               ot='UInt16', of='COG', a_nodata=0, co=c("OVERVIEWS=IGNORE_EXISTING", "RESAMPLING=MODE", "COMPRESS=DEFLATE", "PREDICTOR=2", "BIGTIFF=IF_SAFER", "NUM_THREADS=16"))

#10m version, Alaska and Yukon bbox only
#Note this does make the bbox a bit larger than necessary, (0,0) is a bit south of the data extent
# Use full bounding box of larger Yukon SA vs. the NAB SA
# akyuk_rast <- rast('/data/gis/gis_projects/2019/19-301_ABoVE_Biome_Shift/akvegmap_v2/studyAreas/AKVEG_ModelArea_Rasters_20230330/AlaskaYukon_MapDomain_10m_3338.tif')
# akyuk_sf <- read_sf(path(w, 'gis_projects/2019/19-301_ABoVE_Biome_Shift/akvegmap_v2/studyAreas/AKVEG_Regions_20230330/AKVEG_Regions.gdb'),
                    # layer='AlaskaYukon_MapDomain_3338')

```

Rasterize 10m with smaller study area
```{r rasterize 10m with smaller study area, eval=FALSE}
fire_snap_10m_3338 <- rast(resolution=10, crs='EPSG:3338', extent=c(-5,5,-5,5))
akyuk <- ak_above %>%
  filter(Region == 'North American Beringia and TNP')
fire_10m_3338 <- extend(fire_snap_10m_3338, akyuk, snap='out')
fire_10m_3338

#SLOOOOW
akyuk_fire_rast <- rasterize(akcan_firepoly_3338_vect, fire_10m_3338, 'fire_year', fun='max',
                          filename='/data/gis/gis_projects/2022/22-301_NASA_ABoVE_Biome_Shift/akvegmap_v2/flt32_mrfy_akyuk_1917_2024_10m_3338_v20250418.tif')

gdal_translate('/data/gis/gis_projects/2022/22-301_NASA_ABoVE_Biome_Shift/akvegmap_v2/flt32_mrfy_akyuk_1917_2024_10m_3338_v20250418.tif',
               '/data/gis/gis_projects/2022/22-301_NASA_ABoVE_Biome_Shift/akvegmap_v2/mrfy_akyuk_1917_2024_10m_3338_v20250418.tif',
               ot='UInt16', of='COG', a_nodata=0, co=c("OVERVIEWS=IGNORE_EXISTING", "RESAMPLING=MODE", "COMPRESS=DEFLATE", "PREDICTOR=2", "BIGTIFF=IF_SAFER", "NUM_THREADS=16"))


# Do 30m as AKCAN not AKCAN ABoVE
```


```{r test fasterize on Canada fires}
library()

```
Upload to GEE assets at projects/akveg-map/assets/disturbance


```{Not used bash annual rasters from nbac shapefile 3338 full nback extent}
cd /data/gis/raster_base/Alaska/AKVegMap/disturbance
mkdir -p nbac/v20240530/noncog_3338
mkdir -p nbac/v20240530/cog_3338

for year in `seq 1972 2023`; do
gdal_rasterize \
  -tr 30 30 \
  -te 433005 300015 5400015 4600005  \
  -a YEAR \
  -where "YEAR = ${year}" \
  -a_srs EPSG:3338 \
  -ot UInt16 \
  -of GTiff \
  -co COMPRESS=DEFLATE \
  /data/gis/vector_base/Canada/Fire_History/20250418/nbac_1972_2023_20240530_3338.shp \
  nbac/v20240530/noncog/noncog_nbac_30m_3338_v20240530_${year}.tif

gdal_translate -of cog -co COMPRESS=DEFLATE nbac/v20240530/noncog/noncog_nbac_30m_3338_v20240530_${year}.tif nbac/v20240530/nbac_30m_3338_v20240530_${year}.tif
done

gsutil cp nbac/v20240530/cog_3338 *.tif gs://akveg-data/disturbance/nbac/v20240530/cog_3338/

# Run nbac_annual_to_cog_ic.ipynb to create cog-backed image collection
```

