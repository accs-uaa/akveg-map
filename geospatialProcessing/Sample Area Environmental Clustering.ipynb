{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Area Environmental Clustering\n",
    "\n",
    "**Timm Nawrocki**  \n",
    "Alaska Center for Conservation Science  \n",
    "2019-04-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ---------------------------------------------------------------------------\n",
    "# Sample Area Environmental Clustering\n",
    "# Author: Timm Nawrocki\n",
    "# Created on: 2019-04-16\n",
    "# Usage: Must be executed as a Jupyter Notebook in an ArcGIS Pro Python 3 installation.\n",
    "# Description: \"Sample Area Environmental Clustering\" clusters the environmental variation in samples from sampling areas.\n",
    "# ---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "# Import clustering and data tools from scikit-learn\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set root directory\n",
    "drive = 'F:/'\n",
    "root_directory = os.path.join(drive, 'ACCS_Work/Projects/VegetationEcology/BristolBay_Vegetation/Project_GIS/Data_Output')\n",
    "\n",
    "# Define input dataset\n",
    "sample_file = os.path.join(root_directory, 'sample_environment/EnvironmentalSample_AleknagikNuyakuk.csv')\n",
    "\n",
    "# Define output dataset\n",
    "output_csv = os.path.join(root_directory, 'sample_environment/EnvironmentalSample_Clustered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variable sets\n",
    "predictor_env = ['aspect', 'compoundTopographic', 'dateFreeze', 'dateThaw', 'elevation', 'exposure', 'growingSeason', 'heatLoad', 'moisture', 'precipitation', 'roughness', 'slope', 'summerWarmth', 'surfaceArea', 'surfaceRelief']\n",
    "predictor_may = ['X05May_1_ultraBlue', 'X05May_2_blue', 'X05May_3_green', 'X05May_4_red', 'X05May_5_redEdge1', 'X05May_6_redEdge2', 'X05May_7_redEdge3', 'X05May_8_nearInfrared', 'X05May_8a_redEdge4', 'X05May_11_shortInfrared1', 'X05May_12_shortInfrared2', 'X05May_nbr', 'X05May_ndmi', 'X05May_ndsi', 'X05May_ndvi', 'X05May_ndwi']\n",
    "predictor_jun = ['X06June_1_ultraBlue', 'X06June_2_blue', 'X06June_3_green', 'X06June_4_red', 'X06June_5_redEdge1', 'X06June_6_redEdge2', 'X06June_7_redEdge3', 'X06June_8_nearInfrared', 'X06June_8a_redEdge4', 'X06June_11_shortInfrared1', 'X06June_12_shortInfrared2', 'X06June_nbr', 'X06June_ndmi', 'X06June_ndsi', 'X06June_ndvi', 'X06June_ndwi']\n",
    "predictor_jul = ['X07July_1_ultraBlue', 'X07July_2_blue', 'X07July_3_green', 'X07July_4_red', 'X07July_5_redEdge1', 'X07July_6_redEdge2', 'X07July_7_redEdge3', 'X07July_8_nearInfrared', 'X07July_8a_redEdge4', 'X07July_11_shortInfrared1', 'X07July_12_shortInfrared2', 'X07July_nbr', 'X07July_ndmi', 'X07July_ndsi', 'X07July_ndvi', 'X07July_ndwi']\n",
    "predictor_aug = ['X08August_1_ultraBlue', 'X08August_2_blue', 'X08August_3_green', 'X08August_4_red', 'X08August_5_redEdge1', 'X08August_6_redEdge2', 'X08August_7_redEdge3', 'X08August_8_nearInfrared', 'X08August_8a_redEdge4', 'X08August_11_shortInfrared1', 'X08August_12_shortInfrared2', 'X08August_nbr', 'X08August_ndmi', 'X08August_ndsi', 'X08August_ndvi', 'X08August_ndwi']\n",
    "predictor_sep = ['X09September_1_ultraBlue', 'X09September_2_blue', 'X09September_3_green', 'X09September_4_red', 'X09September_5_redEdge1', 'X09September_6_redEdge2', 'X09September_7_redEdge3', 'X09September_8_nearInfrared', 'X09September_8a_redEdge4', 'X09September_11_shortInfrared1', 'X09September_12_shortInfrared2', 'X09September_nbr', 'X09September_ndmi', 'X09September_ndsi', 'X09September_ndvi', 'X09September_ndwi']\n",
    "predictor_oct = ['X10October_1_ultraBlue', 'X10October_2_blue', 'X10October_3_green', 'X10October_4_red', 'X10October_5_redEdge1', 'X10October_6_redEdge2', 'X10October_7_redEdge3', 'X10October_8_nearInfrared', 'X10October_8a_redEdge4', 'X10October_11_shortInfrared1', 'X10October_12_shortInfrared2', 'X10October_nbr', 'X10October_ndmi', 'X10October_ndsi', 'X10October_ndvi', 'X10October_ndwi']\n",
    "predictor_all = predictor_env + predictor_may + predictor_jun + predictor_jul + predictor_aug + predictor_sep + predictor_oct\n",
    "coordinates = ['POINT_X', 'POINT_Y']\n",
    "cluster = ['cluster']\n",
    "output_fields = coordinates + cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cluster Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded at 2019-04-17 11:12 (Elapsed time: 0:00:07)\n"
     ]
    }
   ],
   "source": [
    "# Start timing function execution\n",
    "start = time.time()\n",
    "# Create data frame of input data\n",
    "sample_data = pd.read_csv(sample_file)\n",
    "# Remove rows with missing values\n",
    "sample_data = sample_data.dropna(axis=0, how='any')\n",
    "# Convert values to floats\n",
    "sample_data[predictor_all] = sample_data[predictor_all].astype(float)\n",
    "# Shuffle data\n",
    "sample_data = shuffle(sample_data)\n",
    "# Split the X data\n",
    "X = sample_data[predictor_all]\n",
    "# End timing function execution and calculate elapsed time\n",
    "end = time.time()\n",
    "elapsed = int(end - start)\n",
    "success_time = datetime.datetime.now()\n",
    "# Report process success\n",
    "out_process = 'Succeeded at {0} (Elapsed time: {1})'.format(success_time.strftime(\"%Y-%m-%d %H:%M\"),\n",
    "                                                            datetime.timedelta(seconds=elapsed))\n",
    "print(out_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded at 2019-04-17 11:12 (Elapsed time: 0:00:00)\n"
     ]
    }
   ],
   "source": [
    "# Start timing function execution\n",
    "start = time.time()\n",
    "# Create a standard scaler for the X data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "# Transform the X data to Guassian distribution using scaler\n",
    "X_scaled = scaler.transform(X)\n",
    "# End timing function execution and calculate elapsed time\n",
    "end = time.time()\n",
    "elapsed = int(end - start)\n",
    "success_time = datetime.datetime.now()\n",
    "# Report process success\n",
    "out_process = 'Succeeded at {0} (Elapsed time: {1})'.format(success_time.strftime(\"%Y-%m-%d %H:%M\"),\n",
    "                                                            datetime.timedelta(seconds=elapsed))\n",
    "print(out_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded at 2019-04-17 11:31 (Elapsed time: 0:18:59)\n"
     ]
    }
   ],
   "source": [
    "# Start timing function execution\n",
    "start = time.time()\n",
    "# Cluster the samples using Agglomerative Clustering with 64 clusters\n",
    "agglom = AgglomerativeClustering(n_clusters=64, affinity='euclidean').fit(X_scaled)\n",
    "# Assign fitted labels to sample data frame\n",
    "sample_data['cluster'] = agglom.labels_\n",
    "# Export sample data frame to csv\n",
    "output_data = sample_data[output_fields]\n",
    "output_data.to_csv(output_csv, header=True, index=False, sep=',', encoding='utf-8')\n",
    "# End timing function execution and calculate elapsed time\n",
    "end = time.time()\n",
    "elapsed = int(end - start)\n",
    "success_time = datetime.datetime.now()\n",
    "# Report process success\n",
    "out_process = 'Succeeded at {0} (Elapsed time: {1})'.format(success_time.strftime(\"%Y-%m-%d %H:%M\"),\n",
    "                                                            datetime.timedelta(seconds=elapsed))\n",
    "print(out_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
