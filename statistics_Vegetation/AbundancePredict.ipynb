{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abundance Predict\n",
    "\n",
    "**Written by Timm Nawrocki**\n",
    "\n",
    "*Last updated Thursday March 21, 2021.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ---------------------------------------------------------------------------\n",
    "# Predict Vegetation Abundance\n",
    "# Author: Timm Nawrocki, Alaska Center for Conservation Science\n",
    "# Created on: 2021-03-21\n",
    "# Usage: Must be executed as a Jupyter Notebook in an Anaconda 3 installation.\n",
    "# Description: \"Predict Vegetation Abundance\" applies the trained classifier and regressor to data in regular point grid\n",
    "# format stored in csv files to create a composite prediction representing the distribution and proportional abundance of the\n",
    "# target species.\n",
    "# ---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set root directory\n",
    "root_folder = '/home/twnawrocki'\n",
    "# Define species, genera, or aggregate name\n",
    "map_group = 'alnus'\n",
    "# Enter machine number\n",
    "machine_number = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grid folder\n",
    "grid_folder = os.path.join(root_folder,\n",
    "                           'extracted_grids')\n",
    "# Define model folder\n",
    "model_folder = os.path.join(root_folder,\n",
    "                           'model_results',\n",
    "                           map_group)\n",
    "# Define prediction folder\n",
    "prediction_folder = os.path.join(root_folder,\n",
    "                                'predicted_tables',\n",
    "                                map_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make output directory if it does not already exist\n",
    "if os.path.exists(prediction_folder) == 0:\n",
    "    os.mkdir(prediction_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variable sets\n",
    "predictor_all = ['aspect', 'wetness', 'elevation', 'slope', 'roughness', 'exposure', 'area', 'relief', 'position',\n",
    "                 'radiation', 'vh', 'vv', 'shortIR1_06', 'shortIR2_06', 'blue_06', 'green_06', 'red_06', 'redge1_06',\n",
    "                 'redge2_06', 'redge3_06', 'nearIR_06', 'redge4_06', 'evi2_06', 'nbr_06', 'ndmi_06', 'ndsi_06', 'ndvi_06',\n",
    "                 'ndwi_06', 'shortIR1_07', 'shortIR2_07', 'blue_07', 'green_07', 'red_07', 'redge1_07', 'redge2_07',\n",
    "                 'redge3_07', 'nearIR_07', 'redge4_07', 'evi2_07', 'nbr_07', 'ndmi_07', 'ndsi_07', 'ndvi_07', 'ndwi_07',\n",
    "                 'shortIR1_08', 'shortIR2_08', 'blue_08', 'green_08', 'red_08', 'redge1_08', 'redge2_08', 'redge3_08',\n",
    "                 'nearIR_08', 'redge4_08', 'evi2_08', 'nbr_08', 'ndmi_08', 'ndsi_08', 'ndvi_08', 'ndwi_08', 'lstWarmth',\n",
    "                 'precip', 'summerWarmth', 'januaryMin']\n",
    "coordinates = ['x', 'y']\n",
    "absence = ['absence']\n",
    "presence = ['presence']\n",
    "response = ['response']\n",
    "prediction = ['prediction']\n",
    "output_columns = coordinates + prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages for file manipulation, data manipulation, and plotting\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import LightGBM gradient boosting implementations\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import LGBMRegressor\n",
    "# Import joblib\n",
    "import joblib\n",
    "# Import timing packages\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to read threshold values from text file\n",
    "def readThreshold(inFile):\n",
    "    threshold_reader = open(inFile, \"r\")\n",
    "    threshold = threshold_reader.readlines()\n",
    "    threshold_reader.close()\n",
    "    outThreshold = float(threshold[0])\n",
    "    return outThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to composite model results\n",
    "def compositePrediction(input_data, presence, response, threshold):\n",
    "    # Define a function to threshold absences and set presences equal to regression response\n",
    "    def compositeRows(row):\n",
    "        if row[presence[0]] < threshold:\n",
    "            return 0\n",
    "        elif row[presence[0]] >= threshold:\n",
    "            if row[response[0]] <= 0:\n",
    "                return 0\n",
    "            elif row[response[0]] > 0:\n",
    "                return round(row[response[0]], 0)\n",
    "    # Apply function to all rows in test data\n",
    "    input_data['prediction'] = input_data.apply(lambda row: compositeRows(row), axis=1)\n",
    "    # Return the test data frame with composited results\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the trained models\n",
    "classifier = joblib.load(os.path.join(model_folder, 'classifier.joblib'))\n",
    "regressor = joblib.load(os.path.join(model_folder, 'regressor.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read thresholds from text files in the workspace folder and store as variables\n",
    "threshold = readThreshold(os.path.join(model_folder, 'threshold.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of input files for the prediction step\n",
    "os.chdir(grid_folder)\n",
    "grid_files = glob.glob('*.csv')\n",
    "# Subset the grid files\n",
    "grid_files = grid_files[((machine_number * 7930) - 7930):((machine_number * 7930) - 1)]\n",
    "grid_length = len(grid_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop through the prediction function for all input files\n",
    "count = 1\n",
    "for grid in grid_files:\n",
    "    # Define the output csv file\n",
    "    output_csv = os.path.join(prediction_folder, grid)\n",
    "    \n",
    "    # Predict output table if it does not already exist\n",
    "    if os.path.exists(output_csv) == 0:\n",
    "        total_start = time.time()\n",
    "        print(f'Predicting grid {count} of {grid_length}...')\n",
    "    \n",
    "        # Identify file path to the input csv file\n",
    "        print('\\tLoading grid data into memory...')\n",
    "        iteration_start = time.time()\n",
    "        input_csv = os.path.join(grid_folder, grid)\n",
    "        # Load the input data\n",
    "        input_data = pd.read_csv(input_csv)\n",
    "        input_data = input_data.rename(columns={'janMin': 'januaryMin'})\n",
    "        input_data = input_data.dropna(axis=0, how='any')\n",
    "        input_data[predictor_all] = input_data[predictor_all].astype(float)\n",
    "        # Define the X data\n",
    "        X_data = input_data[predictor_all].astype(float)\n",
    "        iteration_end = time.time()\n",
    "        iteration_elapsed = int(iteration_end - iteration_start)\n",
    "        iteration_success_time = datetime.datetime.now()\n",
    "        print(f'\\tCompleted at {iteration_success_time.strftime(\"%Y-%m-%d %H:%M\")} (Elapsed time: {datetime.timedelta(seconds=iteration_elapsed)})')\n",
    "        print('\\t----------')\n",
    "    \n",
    "        # Predict the classifier\n",
    "        print('\\tClassifying presence-absence...')\n",
    "        iteration_start = time.time()\n",
    "        classification = classifier.predict_proba(X_data)\n",
    "        # Concatenate predicted values to input data frame\n",
    "        input_data['absence'] = classification[:,0]\n",
    "        input_data['presence'] = classification[:,1]\n",
    "        iteration_end = time.time()\n",
    "        iteration_elapsed = int(iteration_end - iteration_start)\n",
    "        iteration_success_time = datetime.datetime.now()\n",
    "        print(f'\\tCompleted at {iteration_success_time.strftime(\"%Y-%m-%d %H:%M\")} (Elapsed time: {datetime.timedelta(seconds=iteration_elapsed)})')\n",
    "        print('\\t----------')\n",
    "    \n",
    "        # Predict the regressor\n",
    "        print('\\tPredicting foliar cover...')\n",
    "        iteration_start = time.time()\n",
    "        regression = regressor.predict(X_data)\n",
    "        # Concatenate predicted values to input data frame\n",
    "        input_data['response'] = regression\n",
    "        iteration_end = time.time()\n",
    "        iteration_elapsed = int(iteration_end - iteration_start)\n",
    "        iteration_success_time = datetime.datetime.now()\n",
    "        print(f'\\tCompleted at {iteration_success_time.strftime(\"%Y-%m-%d %H:%M\")} (Elapsed time: {datetime.timedelta(seconds=iteration_elapsed)})')\n",
    "        print('\\t----------')\n",
    "    \n",
    "        # Composite the classifier and regressor predictions\n",
    "        print('\\tExporting results...')\n",
    "        iteration_start = time.time()\n",
    "        input_data = compositePrediction(input_data, presence, response, threshold)\n",
    "        # Export prediction to csv\n",
    "        output_data = input_data[output_columns]\n",
    "        output_data.to_csv(output_csv, header=True, index=False, sep=',', encoding='utf-8')\n",
    "        iteration_end = time.time()\n",
    "        iteration_elapsed = int(iteration_end - iteration_start)\n",
    "        iteration_success_time = datetime.datetime.now()\n",
    "        print(f'\\tCompleted at {iteration_success_time.strftime(\"%Y-%m-%d %H:%M\")} (Elapsed time: {datetime.timedelta(seconds=iteration_elapsed)})')\n",
    "        print('\\t----------')\n",
    "    \n",
    "        total_end = time.time()\n",
    "        total_elapsed = int(total_end - total_start)\n",
    "        total_success_time = datetime.datetime.now()\n",
    "        print(f'Iteration completed at {total_success_time.strftime(\"%Y-%m-%d %H:%M\")} (Elapsed time: {datetime.timedelta(seconds=total_elapsed)})')\n",
    "        print('----------')\n",
    "    \n",
    "    else:\n",
    "        print(f'Grid {count} of {grid_length} already predicted.')\n",
    "        print('----------')\n",
    "    \n",
    "    # Increase counter\n",
    "    count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
